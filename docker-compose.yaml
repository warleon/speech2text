services:
  backend:
    build:
      context: ./backend
      args:
        - HUGGING_FACE_TOKEN=${HUGGING_FACE_TOKEN}
        - MODELS_DOWNLOAD_PATH=/models
    restart: unless-stopped
    environment:
      - HUGGING_FACE_TOKEN=${HUGGING_FACE_TOKEN}
    networks:
      - whisper-net
    volumes:
      - ./backend/:/app
      - shared-uploads:/uploads
      - models-downloads:/models
    command: python3 app.py
    ports:
      - 8000:8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 20s
      timeout: 10s
      retries: 10
  frontend:
    build: ./frontend # Path to your Next.js frontend
    ports:
      - "3000:3000"
    networks:
      - whisper-net
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - shared-uploads:/app/uploads
    command: npm run start
  rq-dashboard:
    image: jaredv/rq-docker:0.0.2
    command: rq-dashboard -H rq-server
    ports:
      - 9181:9181
    networks:
      - whisper-net
  rq-server:
    image: redis:alpine
    ports:
      - 6379:6379
    networks:
      - whisper-net

networks:
  whisper-net:
    driver: bridge

volumes:
  shared-uploads:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./frontend/speech2text/uploads
  models-downloads:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./models
